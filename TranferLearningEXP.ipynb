{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbeiTpCKSjgU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oymch2pTUreT"
      },
      "outputs": [],
      "source": [
        "## Step 1: Load and Preprocess Data\n",
        "# Define transformations for images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize images for pre-trained model input\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Standard normalization for pre-trained models\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORcbCftNkwfT"
      },
      "outputs": [],
      "source": [
        "!unzip -qq ./chip_data.zip -d data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S04Rrm9EUokD"
      },
      "outputs": [],
      "source": [
        "# Load dataset from a folder (structured as: dataset/class_name/images)\n",
        "dataset_path = \"./data/dataset/\"\n",
        "train_dataset = datasets.ImageFolder(root=f\"{dataset_path}/train\", transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root=f\"{dataset_path}/test\", transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display some input images\n",
        "def show_sample_images(dataset, num_images=5):\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(5, 5))\n",
        "    for i in range(num_images):\n",
        "        image, label = dataset[i]\n",
        "        image = image.permute(1, 2, 0)  # Convert tensor format (C, H, W) to (H, W, C)\n",
        "        axes[i].imshow(image)\n",
        "        axes[i].set_title(dataset.classes[label])\n",
        "        axes[i].axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "hUQK4yhuyAXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show sample images from the training dataset\n",
        "show_sample_images(train_dataset)"
      ],
      "metadata": {
        "id": "YYQUbifXyBHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnvpyPeVlNNE"
      },
      "outputs": [],
      "source": [
        "# Get the total number of samples in the training dataset\n",
        "print(f\"Total number of training samples: {len(train_dataset)}\")\n",
        "\n",
        "# Get the shape of the first image in the dataset\n",
        "first_image, label = train_dataset[0]\n",
        "print(f\"Shape of the first image: {first_image.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "On2vXFTZlqGS"
      },
      "outputs": [],
      "source": [
        "# Get the total number of samples in the testing dataset\n",
        "\n",
        "\n",
        "# Get the shape of the first image in the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x07EUeWOUsga"
      },
      "outputs": [],
      "source": [
        "# Create DataLoader for batch processing\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWIh8JWbl8xC"
      },
      "outputs": [],
      "source": [
        "## Step 2: Load Pretrained Model and Modify for Transfer Learning\n",
        "# Load a pre-trained VGG19 model\n",
        "# write your code here\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "5k7kl3SDWh1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSJszKztnHJJ"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "# Print model summary\n",
        "summary(model, input_size=(3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeSLtMdTmk3k"
      },
      "outputs": [],
      "source": [
        "# Modify the final fully connected layer to match the dataset classes\n",
        "# Write your code here\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "QXeX0fnffz_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7q9-63GVm3Ea"
      },
      "outputs": [],
      "source": [
        "summary(model, input_size=(3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9JMtRm-oQ9S"
      },
      "outputs": [],
      "source": [
        "# Freeze all layers except the final layer\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False  # Freeze feature extractor layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vo2r75SXodmB"
      },
      "outputs": [],
      "source": [
        "# Include the Loss function and optimizer\n",
        "criterion =\n",
        "optimizer ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sOBDi6zog0x"
      },
      "outputs": [],
      "source": [
        "## Step 3: Train the Model\n",
        "def train_model(model, train_loader,test_loader,num_epochs=10):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        train_losses.append(running_loss / len(train_loader))\n",
        "\n",
        "        # Compute validation loss\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        val_losses.append(val_loss / len(test_loader))\n",
        "        model.train()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_losses[-1]:.4f}, Validation Loss: {val_losses[-1]:.4f}')\n",
        "\n",
        "    # Plot training and validation loss\n",
        "    print(\"Name:        \")\n",
        "    print(\"Register Number:        \")\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss', marker='o')\n",
        "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss', marker='s')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "DdUBPt5sfnPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "# Write your code here\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1HyIpDqcfooh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkyJgGVRoqh5"
      },
      "outputs": [],
      "source": [
        "## Step 4: Test the Model and Compute Confusion Matrix & Classification Report\n",
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    print(\"Name:        \")\n",
        "    print(\"Register Number:        \")\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=train_dataset.classes, yticklabels=train_dataset.classes)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "    # Print classification report\n",
        "    print(\"Name:        \")\n",
        "    print(\"Register Number:        \")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=train_dataset.classes))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnJOwEC9ov9k"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "# write your code here\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeiAImWso1U5"
      },
      "outputs": [],
      "source": [
        "## Step 5: Predict on a Single Image and Display It\n",
        "def predict_image(model, image_index, dataset):\n",
        "    model.eval()\n",
        "    image, label = dataset[image_index]\n",
        "    with torch.no_grad():\n",
        "        # The image is already a tensor, just add batch dimension and send to device\n",
        "        image_tensor = image.unsqueeze(0).to(device)\n",
        "        output = model(image_tensor)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "    class_names = dataset.classes  # Get class labels\n",
        "\n",
        "    # Display the image\n",
        "    # Need to convert the image back to PIL format for display\n",
        "    image_to_display = transforms.ToPILImage()(image)\n",
        "    print(\"Name:        \")\n",
        "    print(\"Register Number:        \")\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(image_to_display)\n",
        "    plt.title(f'Actual: {class_names[label]}\\nPredicted: {class_names[predicted.item()]}')\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inXwcc7vo4wR"
      },
      "outputs": [],
      "source": [
        "# Example Prediction\n",
        "predict_image(model, image_index=55, dataset=test_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Example Prediction\n",
        "predict_image(model, image_index=25, dataset=test_dataset)"
      ],
      "metadata": {
        "id": "Aw5tXR4rXsI5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}